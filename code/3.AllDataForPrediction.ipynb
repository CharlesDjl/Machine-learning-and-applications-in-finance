{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset && DataLoader\n",
    "class HouseDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)  # Convert DataFrame to tensor\n",
    "        self.y = torch.tensor(y.values, dtype=torch.long)  # Convert pd.Series to numpy.ndarray and then to tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# PyTorch\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_prob=0.5, l2_reg=0.001):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "\n",
    "        self.l2_reg = l2_reg ## Adjust the value of l2_reg to find the suitable parameter\n",
    "        \n",
    "        self.best_loss = float('inf')\n",
    "        self.patience = 5\n",
    "        self.current_patience = 0\n",
    "\n",
    "    # Function: Relu(), using 0.15 dropout in every layer to reduce fit\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def l2_regularization(self):\n",
    "        l2_loss = 0\n",
    "        for param in self.parameters():\n",
    "            l2_loss += torch.norm(param, p=2) ** 2\n",
    "        return self.l2_reg * l2_loss\n",
    "    \n",
    "    def early_stop(self, val_loss):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.current_patience = 0\n",
    "        else:\n",
    "            self.current_patience += 1\n",
    "            if self.current_patience >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_loader, test_loader, num_epochs):\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    ## If the pc has cuda, using it to calculate so that the speed is faster\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Move inputs and labels to the same device as the model\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels) + model.l2_regularization()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        scheduler.step() #Using the scheduler to adjust the learning rate every epoch\n",
    "        train_loss = running_loss / len(train_loader) # Calculate the training loss\n",
    "        losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(test_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction every fold\n",
    "def predict_fold(model, test_loader):\n",
    "    fold_true_labels = []\n",
    "    fold_predictions = []\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            fold_true_labels.extend(labels.cpu().numpy())\n",
    "            fold_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    return fold_true_labels, fold_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function, return accuracy, precision, recall and F1 score to evaluate the model\n",
    "def evaluate_fold(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch [1/15], Loss: 0.5891, Val Loss: 0.2692\n",
      "Epoch [2/15], Loss: 0.4856, Val Loss: 0.2426\n",
      "Epoch [3/15], Loss: 0.4408, Val Loss: 0.2340\n",
      "Epoch [4/15], Loss: 0.4071, Val Loss: 0.2272\n",
      "Epoch [5/15], Loss: 0.3832, Val Loss: 0.2255\n",
      "Epoch [6/15], Loss: 0.3616, Val Loss: 0.2261\n",
      "Epoch [7/15], Loss: 0.3435, Val Loss: 0.2260\n",
      "Epoch [8/15], Loss: 0.3320, Val Loss: 0.2235\n",
      "Epoch [9/15], Loss: 0.3157, Val Loss: 0.2215\n",
      "Epoch [10/15], Loss: 0.3109, Val Loss: 0.2199\n",
      "Epoch [11/15], Loss: 0.3066, Val Loss: 0.2263\n",
      "Epoch [12/15], Loss: 0.3015, Val Loss: 0.2258\n",
      "Epoch [13/15], Loss: 0.2958, Val Loss: 0.2219\n",
      "Epoch [14/15], Loss: 0.2963, Val Loss: 0.2237\n",
      "Epoch [15/15], Loss: 0.2878, Val Loss: 0.2230\n",
      "Fold 1 Accuracy: 0.9136\n",
      "Fold 1 Precision: 0.9089\n",
      "Fold 1 Recall: 0.9136\n",
      "Fold 1 F1 Score: 0.9094\n",
      "Fold 1 Confusion Matrix:\n",
      "[[1647   53]\n",
      " [ 122  204]]\n",
      "Fold 2\n",
      "Epoch [1/15], Loss: 0.5924, Val Loss: 0.2466\n",
      "Epoch [2/15], Loss: 0.4889, Val Loss: 0.2341\n",
      "Epoch [3/15], Loss: 0.4423, Val Loss: 0.2272\n",
      "Epoch [4/15], Loss: 0.4061, Val Loss: 0.2217\n",
      "Epoch [5/15], Loss: 0.3792, Val Loss: 0.2204\n",
      "Epoch [6/15], Loss: 0.3654, Val Loss: 0.2213\n",
      "Epoch [7/15], Loss: 0.3454, Val Loss: 0.2191\n",
      "Epoch [8/15], Loss: 0.3275, Val Loss: 0.2158\n",
      "Epoch [9/15], Loss: 0.3257, Val Loss: 0.2200\n",
      "Epoch [10/15], Loss: 0.3055, Val Loss: 0.2179\n",
      "Epoch [11/15], Loss: 0.3041, Val Loss: 0.2167\n",
      "Epoch [12/15], Loss: 0.2995, Val Loss: 0.2189\n",
      "Epoch [13/15], Loss: 0.2961, Val Loss: 0.2166\n",
      "Epoch [14/15], Loss: 0.2930, Val Loss: 0.2125\n",
      "Epoch [15/15], Loss: 0.2912, Val Loss: 0.2111\n",
      "Fold 2 Accuracy: 0.9191\n",
      "Fold 2 Precision: 0.9151\n",
      "Fold 2 Recall: 0.9191\n",
      "Fold 2 F1 Score: 0.9154\n",
      "Fold 2 Confusion Matrix:\n",
      "[[1650   50]\n",
      " [ 114  212]]\n",
      "Fold 3\n",
      "Epoch [1/15], Loss: 0.6047, Val Loss: 0.2572\n",
      "Epoch [2/15], Loss: 0.4833, Val Loss: 0.2510\n",
      "Epoch [3/15], Loss: 0.4415, Val Loss: 0.2477\n",
      "Epoch [4/15], Loss: 0.4094, Val Loss: 0.2427\n",
      "Epoch [5/15], Loss: 0.3825, Val Loss: 0.2372\n",
      "Epoch [6/15], Loss: 0.3593, Val Loss: 0.2361\n",
      "Epoch [7/15], Loss: 0.3414, Val Loss: 0.2331\n",
      "Epoch [8/15], Loss: 0.3286, Val Loss: 0.2334\n",
      "Epoch [9/15], Loss: 0.3155, Val Loss: 0.2328\n",
      "Epoch [10/15], Loss: 0.3129, Val Loss: 0.2322\n",
      "Epoch [11/15], Loss: 0.3064, Val Loss: 0.2329\n",
      "Epoch [12/15], Loss: 0.2951, Val Loss: 0.2313\n",
      "Epoch [13/15], Loss: 0.2949, Val Loss: 0.2335\n",
      "Epoch [14/15], Loss: 0.2951, Val Loss: 0.2384\n",
      "Epoch [15/15], Loss: 0.2855, Val Loss: 0.2319\n",
      "Fold 3 Accuracy: 0.9072\n",
      "Fold 3 Precision: 0.9014\n",
      "Fold 3 Recall: 0.9072\n",
      "Fold 3 F1 Score: 0.9012\n",
      "Fold 3 Confusion Matrix:\n",
      "[[1649   51]\n",
      " [ 137  188]]\n",
      "Fold 4\n",
      "Epoch [1/15], Loss: 0.5867, Val Loss: 0.2714\n",
      "Epoch [2/15], Loss: 0.4822, Val Loss: 0.2439\n",
      "Epoch [3/15], Loss: 0.4406, Val Loss: 0.2372\n",
      "Epoch [4/15], Loss: 0.4007, Val Loss: 0.2387\n",
      "Epoch [5/15], Loss: 0.3804, Val Loss: 0.2364\n",
      "Epoch [6/15], Loss: 0.3581, Val Loss: 0.2327\n",
      "Epoch [7/15], Loss: 0.3409, Val Loss: 0.2301\n",
      "Epoch [8/15], Loss: 0.3317, Val Loss: 0.2298\n",
      "Epoch [9/15], Loss: 0.3252, Val Loss: 0.2325\n",
      "Epoch [10/15], Loss: 0.3130, Val Loss: 0.2282\n",
      "Epoch [11/15], Loss: 0.3068, Val Loss: 0.2327\n",
      "Epoch [12/15], Loss: 0.3009, Val Loss: 0.2266\n",
      "Epoch [13/15], Loss: 0.2906, Val Loss: 0.2284\n",
      "Epoch [14/15], Loss: 0.2920, Val Loss: 0.2288\n",
      "Epoch [15/15], Loss: 0.2891, Val Loss: 0.2300\n",
      "Fold 4 Accuracy: 0.9101\n",
      "Fold 4 Precision: 0.9056\n",
      "Fold 4 Recall: 0.9101\n",
      "Fold 4 F1 Score: 0.9068\n",
      "Fold 4 Confusion Matrix:\n",
      "[[1636   64]\n",
      " [ 118  207]]\n",
      "Fold 5\n",
      "Epoch [1/15], Loss: 0.5978, Val Loss: 0.2650\n",
      "Epoch [2/15], Loss: 0.4773, Val Loss: 0.2491\n",
      "Epoch [3/15], Loss: 0.4344, Val Loss: 0.2460\n",
      "Epoch [4/15], Loss: 0.3997, Val Loss: 0.2354\n",
      "Epoch [5/15], Loss: 0.3811, Val Loss: 0.2377\n",
      "Epoch [6/15], Loss: 0.3543, Val Loss: 0.2335\n",
      "Epoch [7/15], Loss: 0.3378, Val Loss: 0.2330\n",
      "Epoch [8/15], Loss: 0.3318, Val Loss: 0.2307\n",
      "Epoch [9/15], Loss: 0.3190, Val Loss: 0.2336\n",
      "Epoch [10/15], Loss: 0.3098, Val Loss: 0.2290\n",
      "Epoch [11/15], Loss: 0.3016, Val Loss: 0.2276\n",
      "Epoch [12/15], Loss: 0.2977, Val Loss: 0.2271\n",
      "Epoch [13/15], Loss: 0.2934, Val Loss: 0.2290\n",
      "Epoch [14/15], Loss: 0.2848, Val Loss: 0.2282\n",
      "Epoch [15/15], Loss: 0.2917, Val Loss: 0.2269\n",
      "Fold 5 Accuracy: 0.9101\n",
      "Fold 5 Precision: 0.9049\n",
      "Fold 5 Recall: 0.9101\n",
      "Fold 5 F1 Score: 0.9053\n",
      "Fold 5 Confusion Matrix:\n",
      "[[1646   54]\n",
      " [ 128  197]]\n",
      "Average Accuracy: 0.9120\n",
      "Average Precision: 0.9072\n",
      "Average Recall: 0.9120\n",
      "Average F1 Score: 0.9076\n"
     ]
    }
   ],
   "source": [
    "# Load the data from Bank1, Bank2, Bank3\n",
    "data1 = pd.read_csv('../data/Bank1_New.csv')\n",
    "data2 = pd.read_csv('../data/Bank2_New.csv')\n",
    "data3 = pd.read_csv('../data/Bank3_New.csv')\n",
    "\n",
    "# Combine them and reset the index of the data\n",
    "data = pd.concat([data1, data2, data3], ignore_index=True)\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]  # Target variable\n",
    "\n",
    "# Normalize features (except the second to last column)\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = X.iloc[:, :-1]  # Exclude the second to last column (L-3)\n",
    "X_normalized = scaler.fit_transform(X_normalized)\n",
    "\n",
    "# Add the PCA result column back to the normalized features\n",
    "X_normalized = pd.DataFrame(X_normalized, columns=X.columns[:-1])\n",
    "X_normalized[\"L-3\"] = X.iloc[:, -2]  # Add the PCA result column\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model, loss function and optimizer\n",
    "input_size = X.shape[1]\n",
    "output_size = 2\n",
    "model = Net(input_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=32, gamma=0.1)\n",
    "\n",
    "\n",
    "# Training the model\n",
    "num_splits = 5 # K = 5\n",
    "skf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "metrics_per_fold = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    X_train, X_test = X_normalized.iloc[train_index], X_normalized.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    train_dataset = HouseDataset(X_train, y_train)\n",
    "    test_dataset = HouseDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = Net(input_size, output_size)\n",
    "\n",
    "    # Cross-entropy is used to determine how close the actual output is to the desired output\n",
    "    # It is suitable for classification models\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=32, gamma=0.1)\n",
    "\n",
    "    num_epochs = 15\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    losses, val_losses = train_model(model, criterion, optimizer, scheduler, train_loader, test_loader, num_epochs)\n",
    "\n",
    "    fold_true_labels, fold_predictions = predict_fold(model, test_loader)\n",
    "    # Get the evaluation rates every FOLD\n",
    "    fold_accuracy, fold_precision, fold_recall, fold_f1 = evaluate_fold(fold_true_labels, fold_predictions)\n",
    "    print(f\"Fold {fold + 1} Accuracy: {fold_accuracy:.4f}\")\n",
    "    print(f\"Fold {fold + 1} Precision: {fold_precision:.4f}\")\n",
    "    print(f\"Fold {fold + 1} Recall: {fold_recall:.4f}\")\n",
    "    print(f\"Fold {fold + 1} F1 Score: {fold_f1:.4f}\")\n",
    "\n",
    "    metrics_per_fold.append((fold_accuracy, fold_precision, fold_recall, fold_f1))\n",
    "        \n",
    "    fold_confusion_matrix = confusion_matrix(fold_true_labels, fold_predictions)\n",
    "    print(f\"Fold {fold + 1} Confusion Matrix:\\n{fold_confusion_matrix}\")\n",
    "\n",
    "# Final results\n",
    "average_metrics = np.mean(metrics_per_fold, axis=0)\n",
    "print(f\"Average Accuracy: {average_metrics[0]:.4f}\")\n",
    "print(f\"Average Precision: {average_metrics[1]:.4f}\")\n",
    "print(f\"Average Recall: {average_metrics[2]:.4f}\")\n",
    "print(f\"Average F1 Score: {average_metrics[3]:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
